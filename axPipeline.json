{"num": 9, "order_index": 7569, "url": "http://arxiv.org/abs/1608.08305", "authors": ["Ronghang Hu", "Marcus Rohrbach", "Subhashini Venugopalan", "Trevor Darrell"], "abstract": "Image segmentation from referring expressions is a joint vision and language modeling task, where the input is an image and a textual expression describing a particular region in the image; and the goal is to localize and segment the specific image region based on the given expression. One major difficulty to train such language-based image segmentation systems is the lack of datasets with joint vision and text annotations. Although existing vision datasets such as MS COCO provide image captions, there are few datasets with region-level textual annotations for images, and these are often smaller in scale. In this paper, we explore how existing large scale vision-only and text-only datasets can be utilized to train models for image segmentation from referring expressions. We propose a method to address this problem, and show in experiments that our method can help this joint vision and language modeling task with vision-only and text-only data and outperforms previous results.", "title": "[1608.08305] Utilizing Large Scale Vision and Text Datasets for Image Segmentation from Referring Expressions", "sec_subject": "cs.CV"}
{"num": 1, "order_index": 7561, "url": "http://arxiv.org/abs/1608.08614", "authors": ["Minyoung Huh", "Pulkit Agrawal", "Alexei A. Efros"], "abstract": "The tremendous success of features learnt using the ImageNet classification task on a wide range of transfer tasks begs the question: what are the intrinsic properties of the ImageNet dataset that are critical for learning good, general-purpose features? This work provides an empirical investigation of various facets of this question: Is more pre-training data always better? How does feature quality depend on the number of training examples per class? Does adding more object classes improve performance? For the same data budget, how should the data be split into classes? Is fine-grained recognition necessary for learning good features? Given the same number of training classes, is it better to have coarse classes or fine-grained classes? Which is better: more classes or more examples per class?", "title": "[1608.08614] What makes ImageNet good for transfer learning?", "sec_subject": "cs.CV"}
{"num": 7, "order_index": 7567, "url": "http://arxiv.org/abs/1608.08336", "authors": ["Ming Yin", "unbin Gao", "Shengli Xie", "Yi Guo"], "abstract": "The plenty information from multiple views data as well as the complementary information among different views are usually beneficial to various tasks, e.g., clustering, classification, de-noising. Multi-view subspace clustering is based on the fact that the multi-view data are generated from a latent subspace. To recover the underlying subspace structure, the success of the sparse and/or low-rank subspace clustering has been witnessed recently. Despite some state-of-the-art subspace clustering approaches can numerically handle multi-view data, by simultaneously exploring all possible pairwise correlation within views, the high order statistics is often disregarded which can only be captured by simultaneously utilizing all views. As a consequence, the clustering performance for multi-view data is compromised. To address this issue, in this paper, a novel multi-view clustering method is proposed by using \\textit{t-product} in third-order tensor space. Based on the circular convolution operation, multi-view data can be effectively represented by a \\textit{t-linear} combination with sparse and low-rank penalty using \"self-expressiveness\". Our extensive experimental results on facial, object, digits image and text data demonstrate that the proposed method outperforms the state-of-the-art methods in terms of many criteria.", "title": "[1608.08336] Low-rank Multi-view Clustering in Third-Order Tensor Space", "sec_subject": "cs.CV"}
{"num": 6, "order_index": 7566, "url": "http://arxiv.org/abs/1608.08395", "authors": ["Hirokatsu Kataoka", "Yun He", "Soma Shirakabe", "Yutaka Satoh"], "abstract": "Information of time differentiation is extremely important cue for a motion representation. We have applied first-order differential velocity from a positional information, moreover we believe that second-order differential acceleration is also a significant feature in a motion representation. However, an acceleration image based on a typical optical flow includes motion noises. We have not employed the acceleration image because the noises are too strong to catch an effective motion feature in an image sequence. On one hand, the recent convolutional neural networks (CNN) are robust against input noises. In this paper, we employ acceleration-stream in addition to the spatial- and temporal-stream based on the two-stream CNN. We clearly show the effectiveness of adding the acceleration stream to the two-stream CNN.", "title": "[1608.08395] Motion Representation with Acceleration Images", "sec_subject": "cs.CV"}
{"num": 4, "order_index": 7564, "url": "http://arxiv.org/abs/1608.08471", "authors": ["Johannes Stegmaier"], "abstract": "Multidimensional imaging techniques provide powerful ways to examine various kinds of scientific questions. The routinely produced datasets in the terabyte-range, however, can hardly be analyzed manually and require an extensive use of automated image analysis. The present thesis introduces a new concept for the estimation and propagation of uncertainty involved in image analysis operators and new segmentation algorithms that are suitable for terabyte-scale analyses of 3D+t microscopy images.", "title": "[1608.08471] New Methods to Improve Large-Scale Microscopy Image Analysis with Prior Knowledge and Uncertainty", "sec_subject": "cs.CV"}
{"num": 12, "order_index": 7572, "url": "http://arxiv.org/abs/1608.08339", "authors": ["Taehwan Kim"], "abstract": "In this thesis, we study the problem of recognizing video sequences of fingerspelled letters in American Sign Language (ASL). Fingerspelling comprises a significant but relatively understudied part of ASL, and recognizing it is challenging for a number of reasons: It involves quick, small motions that are often highly coarticulated; it exhibits significant variation between signers; and there has been a dearth of continuous fingerspelling data collected. In this work, we propose several types of recognition approaches, and explore the signer variation problem. Our best-performing models are segmental (semi-Markov) conditional random fields using deep neural network-based features. In the signer-dependent setting, our recognizers achieve up to about 8% letter error rates. The signer-independent setting is much more challenging, but with neural network adaptation we achieve up to 17% letter error rates.", "title": "[1608.08339] American Sign Language fingerspelling recognition from video: Methods for unrestricted recognition and signer-independence", "sec_subject": "cs.CV"}
{"num": 5, "order_index": 7565, "url": "http://arxiv.org/abs/1608.08434", "authors": ["Byungjae Lee", "Enkhbayar Erdenee", "Songguo Jin", "Phill Kyu Rhee"], "abstract": "This paper presents a robust multi-class multi-object tracking (MCMOT) formulated by a Bayesian filtering framework. Multi-object tracking for unlimited object classes is conducted by combining detection responses and changing point detection (CPD) algorithm. The CPD model is used to observe abrupt or abnormal changes due to a drift and an occlusion based spatiotemporal characteristics of track states. The ensemble of convolutional neural network (CNN) based object detector and Lucas-Kanede Tracker (KLT) based motion detector is employed to compute the likelihoods of foreground regions as the detection responses of different object classes. Extensive experiments are performed using lately introduced challenging benchmark videos; ImageNet VID and MOT benchmark dataset. The comparison to state-of-the-art video tracking techniques shows very encouraging results.", "title": "[1608.08434] Multi-Class Multi-Object Tracking using Changing Point Detection", "sec_subject": "cs.CV"}
{"num": 8, "order_index": 7568, "url": "http://arxiv.org/abs/1608.08334", "authors": ["Shervin Ardeshir", "Ali Borji"], "abstract": "Thanks to the availability and increasing popularity of Egocentric cameras such as GoPro cameras, glasses, and etc. we have been provided with a plethora of videos captured from the first person perspective. Surveillance cameras and Unmanned Aerial Vehicles(also known as drones) also offer tremendous amount of videos, mostly with top-down or oblique view-point. Egocentric vision and top-view surveillance videos have been studied extensively in the past in the computer vision community. However, the relationship between the two has yet to be explored thoroughly. In this effort, we attempt to explore this relationship by approaching two questions. First, having a set of egocentric videos and a top-view video, can we verify if the top-view video contains all, or some of the egocentric viewers present in the egocentric set? And second, can we identify the egocentric viewers in the content of the top-view video? In other words, can we find the cameramen in the surveillance videos? These problems can become more challenging when the videos are not time-synchronous. Thus we formalize the problem in a way which handles and also estimates the unknown relative time-delays between the egocentric videos and the top-view video. We formulate the problem as a spectral graph matching instance, and jointly seek the optimal assignments and relative time-delays of the videos. As a result, we spatiotemporally localize the egocentric observers in the top-view video. We model each view (egocentric or top) using a graph, and compute the assignment and time-delays in an iterative-alternative fashion.", "title": "[1608.08334] Egocentric Meets Surveillance", "sec_subject": "cs.CV"}
{"num": 3, "order_index": 7563, "url": "http://arxiv.org/abs/1608.08526", "authors": ["Umar Iqbal", "Juergen Gall"], "abstract": "Despite of the recent success of neural networks for human pose estimation, current approaches are limited to pose estimation of a single person and cannot handle humans in groups or crowds. In this work, we propose a method that estimates the poses of multiple persons in an image in which a person can be occluded by another person or might be truncated. To this end, we consider multi-person pose estimation as a joint-to-person association problem. We construct a fully connected graph from a set of detected joint candidates in an image and resolve the joint-to-person association and outlier detection using integer linear programming. Since solving joint-to-person association jointly for all persons in an image is an NP-hard problem and even approximations are expensive, we solve the problem locally for each person. On the challenging MPII Human Pose Dataset for multiple persons, our approach achieves the accuracy of a state-of-the-art method, but it is 6,000 to 19,000 times faster.", "title": "[1608.08526] Multi-Person Pose Estimation with Local Joint-to-Person Associations", "sec_subject": "cs.CV"}
{"num": 5, "order_index": 8315, "url": "http://arxiv.org/abs/1608.08225", "authors": ["Henry W. Lin", "Max Tegmark"], "abstract": "We show how the success of deep learning depends not only on mathematics but also on physics: although well-known mathematical theorems guarantee that neural networks can approximate arbitrary functions well, the class of functions of practical interest can be approximated through \"cheap learning\" with exponentially fewer parameters than generic ones, because they have simplifying properties tracing back to the laws of physics. The exceptional simplicity of physics-based functions hinges on properties such as symmetry, locality, compositionality and polynomial log-probability, and we explore how these properties translate into exceptionally simple neural networks approximating both natural phenomena such as images and abstract representations thereof such as drawings. We further argue that when the statistical process generating the data is of a certain hierarchical form prevalent in physics and machine-learning, a deep neural network can be more efficient than a shallow one. We formalize these claims using information theory and discuss the relation to renormalization group procedures. Various \"no-flattening theorems\" show when these efficient deep networks cannot be accurately approximated by shallow ones without efficiency loss - even for linear networks.", "title": "[1608.08225] Why does deep and cheap learning work so well?", "sec_subject": "cs.LG"}
{"num": 1, "order_index": 8311, "url": "http://arxiv.org/abs/1608.08574", "authors": ["Babatunde Olabenjo"], "abstract": "There are over one million apps on Google Play Store and over half a million publishers. Having such a huge number of apps and developers can pose a challenge to app users and new publishers on the store. Discovering apps can be challenging if apps are not correctly published in the right category, and, in turn, reduce earnings for app developers. Additionally, with over 41 categories on Google Play Store, deciding on the right category to publish an app can be challenging for developers due to the number of categories they have to choose from. Machine Learning has been very useful, especially in classification problems such sentiment analysis, document classification and spam detection. These strategies can also be applied to app categorization on Google Play Store to suggest appropriate categories for app publishers using details from their application.", "title": "[1608.08574] Applying Naive Bayes Classification to Google Play Apps Categorization", "sec_subject": "cs.LG"}
{"num": 3, "order_index": 8313, "url": "http://arxiv.org/abs/1608.08266", "authors": ["Antonio Vergari", "Nicola Di Mauro", "Floriana Esposito"], "abstract": "Sum-Product Networks (SPNs) are recently introduced deep tractable probabilistic models by which several kinds of inference queries can be answered exactly and in a tractable time. Up to now, they have been largely used as black box density estimators, assessed only by comparing their likelihood scores only. In this paper we explore and exploit the inner representations learned by SPNs. We do this with a threefold aim: first we want to get a better understanding of the inner workings of SPNs; secondly, we seek additional ways to evaluate one SPN model and compare it against other probabilistic models, providing diagnostic tools to practitioners; lastly, we want to empirically evaluate how good and meaningful the extracted representations are, as in a classic Representation Learning framework. In order to do so we revise their interpretation as deep neural networks and we propose to exploit several visualization techniques on their node activations and network outputs under different types of inference queries. To investigate these models as feature extractors, we plug some SPNs, learned in a greedy unsupervised fashion on image datasets, in supervised classification learning tasks. We extract several embedding types from node activations by filtering nodes by their type, by their associated feature abstraction level and by their scope. In a thorough empirical comparison we prove them to be competitive against those generated from popular feature extractors as Restricted Boltzmann Machines. Finally, we investigate embeddings generated from random probabilistic marginal queries as means to compare other tractable probabilistic models on a common ground, extending our experiments to Mixtures of Trees.", "title": "[1608.08266] Visualizing and Understanding Sum-Product Networks", "sec_subject": "cs.LG"}
{"num": 2, "order_index": 8312, "url": "http://arxiv.org/abs/1608.08435", "authors": ["Rajasekar Venkatesan", "Meng Joo Er"], "abstract": "In this paper, an Extreme Learning Machine (ELM) based technique for Multi-label classification problems is proposed and discussed. In multi-label classification, each of the input data samples belongs to one or more than one class labels. The traditional binary and multi-class classification problems are the subset of the multi-label problem with the number of labels corresponding to each sample limited to one. The proposed ELM based multi-label classification technique is evaluated with six different benchmark multi-label datasets from different domains such as multimedia, text and biology. A detailed comparison of the results is made by comparing the proposed method with the results from nine state of the arts techniques for five different evaluation metrics. The nine methods are chosen from different categories of multi-label methods. The comparative results shows that the proposed Extreme Learning Machine based multi-label classification technique is a better alternative than the existing state of the art methods for multi-label problems.", "title": "[1608.08435] Multi-Label Classification Method Based on Extreme Learning Machines", "sec_subject": "cs.LG"}
{"num": 11, "order_index": 7571, "url": "http://arxiv.org/abs/1608.08242", "authors": ["Colin Lea", "Rene Vidal", "Austin Reiter", "Gregory D. Hager"], "abstract": "The dominant paradigm for video-based action segmentation is composed of two steps: first, for each frame, compute low-level features using Dense Trajectories or a Convolutional Neural Network that encode spatiotemporal information locally, and second, input these features into a classifier that captures high-level temporal relationships, such as a Recurrent Neural Network (RNN). While often effective, this decoupling requires specifying two separate models, each with their own complexities, and prevents capturing more nuanced long-range spatiotemporal relationships. We propose a unified approach, as demonstrated by our Temporal Convolutional Network (TCN), that hierarchically captures relationships at low-, intermediate-, and high-level time-scales. Our model achieves superior or competitive performance using video or sensor data on three public action segmentation datasets and can be trained in a fraction of the time it takes to train an RNN.", "title": "[1608.08242] Temporal Convolutional Networks: A Unified Approach to Action Segmentation", "sec_subject": "cs.CV"}
{"num": 10, "order_index": 7570, "url": "http://arxiv.org/abs/1608.08251", "authors": ["Igor Polkovnikov"], "abstract": "An effort has been made to show mathematicians some new ideas applied to image analysis. Gray images are presented as tilings. Based on topological properties of the tiling, a number of gray convex hulls: maximal, minimal, and oriented ones are constructed and some are proved. They are constructed with only one operation. Two tilings are used in the Constraint and Allowance types of operations. New type of concavity described: a dale. All operations are parallel, possible to realize clock-less. Convexities define what is the background. They are treated as separate gray objects. There are multiple relations among them and their descendants. Via that, topological size of concavities is proposed. Constructed with the same type of operations, Rays and Angles in a tiling define possible spatial relations. Notions like \"strokes\" are defined through concavities. Unusual effects on levelized gray objects are shown. It is illustrated how alphabet and complex hieroglyphs can be described through concavities and their relations. A hypothesis of living organisms image analysis is proposed. A number of examples with symbols and a human face are calculated with new Asynchwave C++ software library.", "title": "[1608.08251] Construction of Convex Sets on Quadrilateral Ordered Tiles or Graphs with Propagation Neighborhood Operations. Dales, Concavity Structures. Application to Gray Image Analysis of Human-Readable Shapes", "sec_subject": "cs.CV"}
{"num": 2, "order_index": 7562, "url": "http://arxiv.org/abs/1608.08596", "authors": ["Matti Raitoharju", "Samu Kallio", "Matti Pellikka"], "abstract": "We present an empirical model for noises in color measurements from OLED displays. According to measured data the noise is not isotropic in the XYZ space, instead most of the noise is along an axis that is parallel to a vector from origin to measured XYZ vector. The presented empirical model is simple and depends only on the measured XYZ values. Our tests show that the variations between multiple panels of the same type have similar distribution as the temporal noise in measurements from a single panel, but a larger magnitude.", "title": "[1608.08596] A statistical model of tristimulus measurements within and between OLED displays", "sec_subject": "cs.CV"}
{"num": 1, "order_index": 7461, "url": "http://arxiv.org/abs/1608.08515", "authors": ["Ivana Balazevic", "Mikio Braun", "Klaus-Robert M\u00fcller"], "abstract": "With the constant growth of the World Wide Web and the number of documents in different languages accordingly, the need for reliable language detection tools has increased as well. Platforms such as Twitter with predominantly short texts are becoming important information resources, which additionally imposes the need for short texts language detection algorithms. In this paper, we show how incorporating personalized user-specific information into the language detection algorithm leads to an important improvement of detection results. To choose the best algorithm for language detection for short text messages, we investigate several machine learning approaches. These approaches include the use of the well-known classifiers such as SVM and logistic regression, a dictionary based approach, and a probabilistic model based on modified Kneser-Ney smoothing. Furthermore, the extension of the probabilistic model to include additional user-specific information such as evidence accumulation per user and user interface language is explored, with the goal of improving the classification performance. The proposed approaches are evaluated on randomly collected Twitter data containing Latin as well as non-Latin alphabet languages and the quality of the obtained results is compared, followed by the selection of the best performing algorithm. This algorithm is then evaluated against two already existing general language detection tools: Chromium Compact Language Detector 2 (CLD2) and langid, where our method significantly outperforms the results achieved by both of the mentioned methods. Additionally, a preview of benefits and possible applications of having a reliable language detection algorithm is given.", "title": "[1608.08515] Language Detection For Short Text Messages In Social Media", "sec_subject": "cs.CL"}
