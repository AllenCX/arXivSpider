{"authors": ["F. M. Ngol\u00e8 Mboula", "J.-L. Starck", "K. Okumura", "J. Amiaux", "P. Hudelot"], "title": "[1608.08104] Constraint matrix factorization for space variant PSFs fiel restoration", "sec_subject": "cs.CV", "url": "http://arxiv.org/abs/1608.08104", "order_index": 7565, "num": 5, "abstract": "Context: in large-scale spatial surveys, the Point Spread Function (PSF) varies across the instrument ?eld of view (FOV). Local measurements of the PSFs are given by the isolated stars images. Yet, these estimates may not be directly usable for post-processings because of the observational noise and potentially the aliasing. Aims: given a set of aliased and noisy stars images from a telescope, we want to estimate well-resolved and noise-free PSFs at the observed stars positions, in particular, exploiting the spatial correlation of the PSFs across the FOV. Contributions: we introduce RCA (Resolved Components Analysis) which is a noise-robust dimension reduction and super-resolution method based on matrix- factorization. We propose an original way of using the PSFs spatial correlation in the restoration process through sparsity. The introduced formalism can be applied to correlated data sets with respect to any euclidean parametric space. Results: we tested our method on simulated monochromatic PSFs of Euclid telescope (launch planned for 2020). The proposed method outperforms existing PSFs restoration and dimension reduction methods. We show that a coupled sparsity constraint on individual PSFs and their spatial distribution yields a signi?cant improvement on both the restored PSFs shapes and the PSFs subspace identi?cation, in presence of aliasing. Perspectives: RCA can be naturally extended to account for the wavelength dependency of the PSFs."}
{"authors": ["Nader Mahmoud", "I\u00f1igo Cirauqui", "Alexandre Hostettler", "Christophe Doignon", "Luc Soler", "Jacques Marescaux", "J.M.M. Montiel"], "title": "[1608.08149] ORBSLAM-based Endoscope Tracking and 3D Reconstruction", "sec_subject": "cs.CV", "url": "http://arxiv.org/abs/1608.08149", "order_index": 7563, "num": 3, "abstract": "We aim to track the endoscope location inside the surgical scene and provide 3D reconstruction, in real-time, from the sole input of the image sequence captured by the monocular endoscope. This information offers new possibilities for developing surgical navigation and augmented reality applications. The main benefit of this approach is the lack of extra tracking elements which can disturb the surgeon performance in the clinical routine. It is our first contribution to exploit ORBSLAM, one of the best performing monocular SLAM algorithms, to estimate both of the endoscope location, and 3D structure of the surgical scene. However, the reconstructed 3D map poorly describe textureless soft organ surfaces such as liver. It is our second contribution to extend ORBSLAM to be able to reconstruct a semi-dense map of soft organs. Experimental results on in-vivo pigs, shows a robust endoscope tracking even with organs deformations and partial instrument occlusions. It also shows the reconstruction density, and accuracy against ground truth surface obtained from CT."}
{"authors": ["Jianhong Wang", "Tian Lan", "Xu Zhang", "Limin Luo"], "title": "[1608.07664] Spatio-temporal Aware Non-negative Component Representation for Action Recognition", "sec_subject": "cs.CV", "url": "http://arxiv.org/abs/1608.07664", "order_index": 7581, "num": 21, "abstract": "This paper presents a novel mid-level representation for action recognition, named spatio-temporal aware non-negative component representation (STANNCR). The proposed STANNCR is based on action component and incorporates the spatial-temporal information. We first introduce a spatial-temporal distribution vector (STDV) to model the distributions of local feature locations in a compact and discriminative manner. Then we employ non-negative matrix factorization (NMF) to learn the action components and encode the video samples. The action component considers the correlations of visual words, which effectively bridge the sematic gap in action recognition. To incorporate the spatial-temporal cues for final representation, the STDV is used as the part of graph regularization for NMF. The fusion of spatial-temporal information makes the STANNCR more discriminative, and our fusion manner is more compact than traditional method of concatenating vectors. The proposed approach is extensively evaluated on three public datasets. The experimental results demonstrate the effectiveness of STANNCR for action recognition."}
{"authors": ["Yao Sui", "Guanghui Wang", "Yafei Tang", "Li Zhang"], "title": "[1608.08171] Tracking Completion", "sec_subject": "cs.CV", "url": "http://arxiv.org/abs/1608.08171", "order_index": 7562, "num": 2, "abstract": "A fundamental component of modern trackers is an online learned tracking model, which is typically modeled either globally or lo- cally. The two kinds of models perform differently in terms of effectiveness and robustness under different challenging situations. This work exploits the advantages of both models. A subspace model, from a global perspec- tive, is learned from previously obtained targets via rank-minimization to address the tracking, and a pixel-level local observation is leveraged si- multaneously, from a local point of view, to augment the subspace model. A matrix completion method is employed to integrate the two models. Unlike previous tracking methods, which locate the target among all fully observed target candidates, the proposed approach first estimates an expected target via the matrix completion through partially observed target candidates, and then, identifies the target according to the esti- mation accuracy with respect to the target candidates. Specifically, the tracking is formulated as a problem of target appearance estimation. Extensive experiments on various challenging video sequences verify the effectiveness of the proposed approach and demonstrate that the pro- posed tracker outperforms other popular state-of-the-art trackers."}
{"authors": ["Xiaojie Jin", "Yunpeng Chen", "Jiashi Feng", "Zequn Jie", "Shuicheng Yan"], "title": "[1608.07706] Multi-Path Feedback Recurrent Neural Network for Scene Parsing", "sec_subject": "cs.CV", "url": "http://arxiv.org/abs/1608.07706", "order_index": 7580, "num": 20, "abstract": "In this paper, we consider the scene parsing problem. We propose a novel \\textbf{M}ulti-\\textbf{P}ath \\textbf{F}eedback recurrent neural network (MPF-RNN) to enhance the capability of RNNs on modeling long-range context information at multiple levels and better distinguish pixels that are easy to confuse in pixel-wise classification."}
{"authors": ["Yipin Zhou", "Tamara L. Berg"], "title": "[1608.07724] Learning Temporal Transformations From Time-Lapse Videos", "sec_subject": "cs.CV", "url": "http://arxiv.org/abs/1608.07724", "order_index": 7578, "num": 18, "abstract": "Based on life-long observations of physical, chemical, and biologic phenomena in the natural world, humans can often easily picture in their minds what an object will look like in the future. But, what about computers? In this paper, we learn computational models of object transformations from time-lapse videos. In particular, we explore the use of generative models to create depictions of objects at future times. These models explore several different prediction tasks: generating a future state given a single depiction of an object, generating a future state given two depictions of an object at different times, and generating future states recursively in a recurrent framework. We provide both qualitative and quantitative evaluations of the generated results, and also conduct a human evaluation to compare variations of our models."}
{"authors": ["Mohamed Aly", "Wolfgang Heidrich"], "title": "[1608.07802] MindX: Denoising Mixed Impulse Poisson-Gaussian Noise Using Proximal Algorithms", "sec_subject": "cs.CV", "url": "http://arxiv.org/abs/1608.07802", "order_index": 7577, "num": 17, "abstract": "We present a novel algorithm for blind denoising of images corrupted by mixed impulse, Poisson, and Gaussian noises. The algorithm starts by applying the Anscombe variance-stabilizing transformation to convert the Poisson into white Gaussian noise. Then it applies a combinatorial optimization technique to denoise the mixed impulse Gaussian noise using proximal algorithms. The result is then processed by the inverse Anscombe transform. We compare our algorithm to state of the art methods on standard images, and show its superior performance in various noise conditions."}
{"authors": ["Trinh Van Chien", "Khanh Quoc Dinh", "Viet Anh Nguyen", "Byeungwoo Jeon"], "title": "[1608.07813] Total variation reconstruction for compressive sensing using nonlocal Lagrangian multiplier", "sec_subject": "cs.CV", "url": "http://arxiv.org/abs/1608.07813", "order_index": 7575, "num": 15, "abstract": "Total variation has proved its effectiveness in solving inverse problems for compressive sensing. Besides, the nonlocal means filter used as regularization preserves texture better for recovered images, but it is quite complex to implement. In this paper, based on existence of both noise and image information in the Lagrangian multiplier, we propose a simple method in term of implementation called nonlocal Lagrangian multiplier (NLLM) in order to reduce noise and boost useful image information. Experimental results show that the proposed NLLM is superior both in subjective and objective qualities of recovered image over other recovery algorithms."}
{"authors": ["Yuval Atzmon", "Jonathan Berant", "Vahid Kezami", "Amir Globerson", "Gal Chechik"], "title": "[1608.07639] Learning to generalize to new compositions in image understanding", "sec_subject": "cs.CV", "url": "http://arxiv.org/abs/1608.07639", "order_index": 7582, "num": 22, "abstract": "Recurrent neural networks have recently been used for learning to describe images using natural language. However, it has been observed that these models generalize poorly to scenes that were not observed during training, possibly depending too strongly on the statistics of the text in the training data. Here we propose to describe images using short structured representations, aiming to capture the crux of a description. These structured representations allow us to tease-out and evaluate separately two types of generalization: standard generalization to new images with similar scenes, and generalization to new combinations of known entities. We compare two learning approaches on the MS-COCO dataset: a state-of-the-art recurrent network based on an LSTM (Show, Attend and Tell), and a simple structured prediction model on top of a deep network. We find that the structured model generalizes to new compositions substantially better than the LSTM, ~7 times the accuracy of predicting structured representations. By providing a concrete method to quantify generalization for unseen combinations, we argue that structured representations and compositional splits are a useful benchmark for image captioning, and advocate compositional models that capture linguistic and visual structure."}
{"authors": ["Seyed-Mohsen Moosavi-Dezfooli", "Alhussein Fawzi", "Pascal Frossard"], "title": "[1511.04599] DeepFool: a simple and accurate method to fool deep neural networks", "sec_subject": "cs.CV", "url": "http://arxiv.org/abs/1511.04599", "order_index": 7586, "num": 26, "abstract": "State-of-the-art deep neural networks have achieved impressive results on many image classification tasks. However, these same architectures have been shown to be unstable to small, well sought, perturbations of the images. Despite the importance of this phenomenon, no effective methods have been proposed to accurately compute the robustness of state-of-the-art deep classifiers to such perturbations on large-scale datasets. In this paper, we fill this gap and propose the DeepFool algorithm to efficiently compute perturbations that fool deep networks, and thus reliably quantify the robustness of these classifiers. Extensive experimental results show that our approach outperforms recent methods in the task of computing adversarial perturbations and making classifiers more robust."}
{"authors": ["Danna Gurari", "Kristen Grauman"], "title": "[1608.08188] Visual Question: Predicting If a Crowd Will Agree on the Answer", "sec_subject": "cs.CV", "url": "http://arxiv.org/abs/1608.08188", "order_index": 7584, "num": 24, "abstract": "Visual question answering (VQA) systems are emerging from a desire to empower users to ask any natural language question about visual content and receive a valid answer in response. However, close examination of the VQA problem reveals an unavoidable, entangled problem that multiple humans may or may not always agree on a single answer to a visual question. We train a model to automatically predict from a visual question whether a crowd would agree on a single answer. We then propose how to exploit this system in a novel application to efficiently allocate human effort to collect answers to visual questions. Specifically, we propose a crowdsourcing system that automatically solicits fewer human responses when answer agreement is expected and more human responses when answer disagreement is expected. Our system improves upon existing crowdsourcing systems, typically eliminating at least 20% of human effort with no loss to the information collected from the crowd."}
{"authors": ["Chandrajit M", "Girisha R", "Vasudev T", "Ashok C B"], "title": "[1608.07807] Cast and Self Shadow Segmentation in Video Sequences using Interval based Eigen Value Representation", "sec_subject": "cs.CV", "url": "http://arxiv.org/abs/1608.07807", "order_index": 7576, "num": 16, "abstract": "Tracking of motion objects in the surveillance videos is useful for the monitoring and analysis. The performance of the surveillance system will deteriorate when shadows are detected as moving objects. Therefore, shadow detection and elimination usually benefits the next stages. To overcome this issue, a method for detection and elimination of shadows is proposed. This paper presents a method for segmenting moving objects in video sequences based on determining the Euclidian distance between two pixels considering neighborhood values in temporal domain. Further, a method that segments cast and self shadows in video sequences by computing the Eigen values for the neighborhood of each pixel is proposed. The dual-map for cast and self shadow pixels is represented based on the interval of Eigen values. The proposed methods are tested on the benchmark IEEE CHANGE DETECTION 2014 dataset."}
{"authors": ["Qinghai Gao"], "title": "[1608.07897] Using k-nearest neighbors to construct cancelable minutiae templates", "sec_subject": "cs.CV", "url": "http://arxiv.org/abs/1608.07897", "order_index": 7573, "num": 13, "abstract": "Fingerprint is widely used in a variety of applications. Security measures have to be taken to protect the privacy of fingerprint data. Cancelable biometrics is proposed as an effective mechanism of using and protecting biometrics. In this paper we propose a new method of constructing cancelable fingerprint template by combining real template with synthetic template. Specifically, each user is given one synthetic minutia template generated with random number generator."}
{"authors": ["Bo Li", "Tianlei Zhang", "Tian Xia"], "title": "[1608.07916] Vehicle Detection from 3D Lidar Using Fully Convolutional Network", "sec_subject": "cs.CV", "url": "http://arxiv.org/abs/1608.07916", "order_index": 7572, "num": 12, "abstract": "Convolutional network techniques have recently achieved great success in vision based detection tasks. This paper introduces the recent development of our research on transplanting the fully convolutional network technique to the detection tasks on 3D range scan data. Specifically, the scenario is set as the vehicle detection task from the range data of Velodyne 64E lidar. We proposes to present the data in a 2D point map and use a single 2D end-to-end fully convolutional network to predict the objectness confidence and the bounding boxes simultaneously. By carefully design the bounding box encoding, it is able to predict full 3D bounding boxes even using a 2D convolutional network. Experiments on the KITTI dataset shows the state-of-the-art performance of the proposed method."}
{"authors": ["Aviv Eisenschtat", "Lior Wolf"], "title": "[1608.07973] Capturing Deep Correlations with 2-Way Nets", "sec_subject": "cs.CV", "url": "http://arxiv.org/abs/1608.07973", "order_index": 7570, "num": 10, "abstract": "We present a noval, bi-directional mapping neural network architecture for the task of matching vectors from two data-sources. Our approach employs two tied neural network channels to project two views into a common, maximally correlated space, using the euclidean loss. To achieve both maximally correlated projections we built an encoder-decoder framework composed of two parallel networks each captures the features of each of the views. We show a direct link between the correlation loss and euclidean loss enabling the use of euclidean loss for optimizing correlation maximization problem. To overcome common euclidean regression optimization problems, we incorporated batch-normalization layers and dropout layers adapted to the model at hand. We show state of the art results on a number of computer vision matching tasks including MNIST image matching and sentence-image matching on the flickr8k and flickr30k datasets."}
{"authors": ["Seoung Wug Oh", "Seon Joo Kim"], "title": "[1608.07951] Approaching the Computational Color Constancy as a Classification Problem through Deep Learning", "sec_subject": "cs.CV", "url": "http://arxiv.org/abs/1608.07951", "order_index": 7571, "num": 11, "abstract": "Computational color constancy refers to the problem of computing the illuminant color so that the images of a scene under varying illumination can be normalized to an image under the canonical illumination. In this paper, we adopt a deep learning framework for the illumination estimation problem. The proposed method works under the assumption of uniform illumination over the scene and aims for the accurate illuminant color computation. Specifically, we trained the convolutional neural network to solve the problem by casting the color constancy problem as an illumination classification problem. We designed the deep learning architecture so that the output of the network can be directly used for computing the color of the illumination. Experimental results show that our deep network is able to extract useful features for the illumination estimation and our method outperforms all previous color constancy methods on multiple test datasets."}
{"authors": ["Yun He", "Soma Shirakabe", "Yutaka Satoh", "Hirokatsu Kataoka"], "title": "[1608.07876] Human Action Recognition without Human", "sec_subject": "cs.CV", "url": "http://arxiv.org/abs/1608.07876", "order_index": 7574, "num": 14, "abstract": "The objective of this paper is to evaluate \"human action recognition without human\". Motion representation is frequently discussed in human action recognition. We have examined several sophisticated options, such as dense trajectories (DT) and the two-stream convolutional neural network (CNN). However, some features from the background could be too strong, as shown in some recent studies on human action recognition. Therefore, we considered whether a background sequence alone can classify human actions in current large-scale action datasets (e.g., UCF101)."}
{"authors": ["Yao Sui", "Ziming Zhang", "Guanghui Wang", "Yafei Tang", "Li Zhang"], "title": "[1608.08173] Real-Time Visual Tracking: Promoting the Robustness of Correlation Filter Learning", "sec_subject": "cs.CV", "url": "http://arxiv.org/abs/1608.08173", "order_index": 7561, "num": 1, "abstract": "Correlation filtering based tracking model has received lots of attention and achieved great success in real-time tracking, howev- er, the lost function in current correlation filtering paradigm could not reliably response to the appearance changes caused by occlusion and il- lumination variations. This study intends to promote the robustness of the correlation filter learning. By exploiting the anisotropy of the filter response, three sparsity related loss functions are proposed to alleviate the overfitting issue of previous methods and improve the overall tracking performance. As a result, three real-time trackers are implemented. Ex- tensive experiments in various challenging situations demonstrate that the robustness of the learned correlation filter has been greatly improved via the designed loss functions. In addition, the study reveals, from an ex- perimental perspective, how different loss functions essentially influence the tracking performance. An important conclusion is that the sensitivity of the peak values of the filter in successive frames is consistent with the tracking performance. This is a useful reference criterion in designing a robust correlation filter for visual tracking."}
{"authors": ["Amritanshu Agrawal", "Wei Fu", "Tim Menzies"], "title": "[1608.08176] What is Wrong with Topic Modeling? (and How to Fix it Using Search-based SE)", "sec_subject": "cs.CL", "url": "http://arxiv.org/abs/1608.08176", "order_index": 7468, "num": 8, "abstract": "Topic Modeling finds human-readable structures in large sets of unstructured SE data. A widely used topic modeler is Latent Dirichlet Allocation. When run on SE data, LDA suffers from \"order effects\" i.e. different topics be generated if the training data was shuffled into a different order. Such order effects introduce a systematic error for any study that uses topics to make conclusions. This paper introduces LDADE, a Search-Based SE tool that tunes LDA's parameters using DE (Differential Evolution). LDADE has been tested on data from a programmer information exchange site (Stackoverflow), title and abstract text of thousands of SE papers, and software defect reports from NASA. Results were collected across different implementations of LDA (Python+Scikit-Learn, Scala+Spark); across different platforms (Linux, Macintosh) and for different kinds of LDAs (the traditional VEM method, or using Gibbs sampling). In all tests, the pattern was the same: LDADE's tunings dramatically reduces topic instability. The implications of this study for other software analytics tasks is now an open and pressing issue. In how many domains can search-based SE dramatically improve software analytics?"}
{"authors": ["Gerda Bortsova", "Michael Sterr", "Lichao Wang", "Fausto Milletari", "Nassir Navab", "Anika B\u00f6ttcher", "Heiko Lickert", "Fabian Theis", "Tingying Peng"], "title": "[1608.07616] Mitosis Detection in Intestinal Crypt Images with Hough Forest and Conditional Random Fields", "sec_subject": "cs.CV", "url": "http://arxiv.org/abs/1608.07616", "order_index": 7583, "num": 23, "abstract": "Intestinal enteroendocrine cells secrete hormones that are vital for the regulation of glucose metabolism but their differentiation from intestinal stem cells is not fully understood. Asymmetric stem cell divisions have been linked to intestinal stem cell homeostasis and secretory fate commitment. We monitored cell divisions using 4D live cell imaging of cultured intestinal crypts to characterize division modes by means of measurable features such as orientation or shape. A statistical analysis of these measurements requires annotation of mitosis events, which is currently a tedious and time-consuming task that has to be performed manually. To assist data processing, we developed a learning based method to automatically detect mitosis events. The method contains a dual-phase framework for joint detection of dividing cells (mothers) and their progeny (daughters). In the first phase we detect mother and daughters independently using Hough Forest whilst in the second phase we associate mother and daughters by modelling their joint probability as Conditional Random Field (CRF). The method has been evaluated on 32 movies and has achieved an AUC of 72%, which can be used in conjunction with manual correction and dramatically speed up the processing pipeline."}
{"authors": ["Junqi Jin", "Ziang Yan", "Kun Fu", "Nan Jiang", "Changshui Zhang"], "title": "[1608.07892] Optimizing Recurrent Neural Networks Architectures under Time Constraints", "sec_subject": "cs.LG", "url": "http://arxiv.org/abs/1608.07892", "order_index": 8326, "num": 16, "abstract": "Recurrent neural network (RNN)'s architecture is a key factor influencing its performance. We propose algorithms to optimize hidden sizes under running time constraint. We convert the discrete optimization into a subset selection problem. By novel transformations, the objective function becomes submodular and constraint becomes supermodular. A greedy algorithm with bounds is suggested to solve the transformed problem. And we show how transformations influence the bounds. To speed up optimization, surrogate functions are proposed which balance exploration and exploitation. Experiments show that our algorithms can find more accurate models or faster models than manually tuned state-of-the-art and random search. We also compare popular RNN architectures using our algorithms."}
{"authors": ["Nicolas Flammarion", "Balamurugan Palaniappan", "Francis Bach"], "title": "[1608.08052] Robust Discriminative Clustering with Sparse Regularizers", "sec_subject": "cs.LG", "url": "http://arxiv.org/abs/1608.08052", "order_index": 8324, "num": 14, "abstract": "Clustering high-dimensional data often requires some form of dimensionality reduction, where clustered variables are separated from \"noise-looking\" variables. We cast this problem as finding a low-dimensional projection of the data which is well-clustered. This yields a one-dimensional projection in the simplest situation with two clusters, and extends naturally to a multi-label scenario for more than two clusters. In this paper, (a) we first show that this joint clustering and dimension reduction formulation is equivalent to previously proposed discriminative clustering frameworks, thus leading to convex relaxations of the problem, (b) we propose a novel sparse extension, which is still cast as a convex relaxation and allows estimation in higher dimensions, (c) we propose a natural extension for the multi-label scenario, (d) we provide a new theoretical analysis of the performance of these formulations with a simple probabilistic model, leading to scalings over the form $d=O(\\sqrt{n})$ for the affine invariant case and $d=O(n)$ for the sparse case, where $n$ is the number of examples and $d$ the ambient dimension, and finally, (e) we propose an efficient iterative algorithm with running-time complexity proportional to $O(nd^2)$, improving on earlier algorithms which had quadratic complexity in the number of examples."}
{"authors": ["Ji Xu", "Daniel Hsu", "Arian Maleki"], "title": "[1608.07630] Global analysis of Expectation Maximization for mixtures of two Gaussians", "sec_subject": "cs.LG", "url": "http://arxiv.org/abs/1608.07630", "order_index": 8328, "num": 18, "abstract": "Expectation Maximization (EM) is among the most popular algorithms for estimating parameters of statistical models. However, EM, which is an iterative algorithm based on the maximum likelihood principle, is generally only guaranteed to find stationary points of the likelihood objective, and these points may be far from any maximizer. This article addresses this disconnect between the statistical principles behind EM and its algorithmic properties. Specifically, it provides a global analysis of EM for specific models in which the observations comprise an i.i.d. sample from a mixture of two Gaussians. This is achieved by (i) studying the sequence of parameters from idealized execution of EM in the infinite sample limit, and fully characterizing the limit points of the sequence in terms of the initial parameters; and then (ii) based on this convergence analysis, establishing statistical consistency (or lack thereof) for the actual sequence of parameters produced by EM."}
{"authors": ["Fei Li", "Meishan Zhang", "Guohong Fu", "Tao Qian", "Donghong Ji"], "title": "[1608.07720] A Bi-LSTM-RNN Model for Relation Classification Using Low-Cost Sequence Features", "sec_subject": "cs.CL", "url": "http://arxiv.org/abs/1608.07720", "order_index": 7466, "num": 6, "abstract": "Relation classification is associated with many potential applications in the artificial intelligence area. Recent approaches usually leverage neural networks based on structure features such as syntactic or dependency features to solve this problem. However, high-cost structure features make such approaches inconvenient to be directly used. In addition, structure features are probably domain-dependent. Therefore, this paper proposes a bi-directional long-short-term-memory recurrent-neural-network (Bi-LSTM-RNN) model based on low-cost sequence features to address relation classification. This model divides a sentence or text segment into five parts, namely two target entities and their three contexts. It learns the representations of entities and their contexts, and uses them to classify relations. We evaluate our model on two standard benchmark datasets in different domains, namely SemEval-2010 Task 8 and BioNLP-ST 2016 Task BB3. In the former dataset, our model achieves comparable performance compared with other models using sequence features. In the latter dataset, our model obtains the third best results compared with other models in the official evaluation. Moreover, we find that the context between two target entities plays the most important role in relation classification. Furthermore, statistic experiments show that the context between two target entities can be used as an approximate replacement of the shortest dependency path when dependency parsing is not used."}
{"authors": ["Shih-Chieh Su"], "title": "[1608.07625] Large Scale Behavioral Analytics via Topical Interaction", "sec_subject": "cs.LG", "url": "http://arxiv.org/abs/1608.07625", "order_index": 8321, "num": 11, "abstract": "We propose the split-diffuse (SD) algorithm that takes the output of an existing dimension reduction algorithm, and distributes the data points uniformly across the visualization space. The result, called the topic grids, is a set of grids on various topics which are generated from the free-form text content of any domain of interest. The topic grids efficiently utilizes the visualization space to provide visual summaries for massive data. Topical analysis, comparison and interaction can be performed on the topic grids in a more perceivable way."}
{"authors": ["R\u00e9mi Flamary", "Marco Cuturi", "Nicolas Courty", "Alain Rakotomamonjy"], "title": "[1608.08063] Wasserstein Discriminant Analysis", "sec_subject": "cs.LG", "url": "http://arxiv.org/abs/1608.08063", "order_index": 8323, "num": 13, "abstract": "Wasserstein Discriminant Analysis (WDA) is a new supervised method that can improve classification of high-dimensional data by computing a suitable linear map onto a lower dimensional subspace. Following the blueprint of classical Linear Discriminant Analysis (LDA), WDA selects the projection matrix that maximizes the ratio of two quantities: the dispersion of projected points coming from different classes, divided by the dispersion of projected points coming from the same class. To quantify dispersion, WDA uses regularized Wasserstein distances, rather than cross-variance measures which have been usually considered, notably in LDA. Thanks to the the underlying principles of optimal transport, WDA is able to capture both global (at distribution scale) and local (at samples scale) interactions between classes. Regularized Wasserstein distances can be computed using the Sinkhorn matrix scaling algorithm; We show that the optimization of WDA can be tackled using automatic differentiation of Sinkhorn iterations. Numerical experiments show promising results both in terms of prediction and visualization on toy examples and real life datasets such as MNIST and on deep features obtained from a subset of the Caltech dataset."}
{"authors": ["Sahar Imtiaz", "Hadi Ghauch", "M. Mahboob Ur Rahman", "George Koudouridis", "James Gross"], "title": "[1608.07949] Learning-Based Resource Allocation Scheme for TDD-Based CRAN System", "sec_subject": "cs.LG", "url": "http://arxiv.org/abs/1608.07949", "order_index": 8325, "num": 15, "abstract": "Explosive growth in the use of smart wireless devices has necessitated the provision of higher data rates and always-on connectivity, which are the main motivators for designing the fifth generation (5G) systems. To achieve higher system efficiency, massive antenna deployment with tight coordination is one potential strategy for designing 5G systems, but has two types of associated system overhead. First is the synchronization overhead, which can be reduced by implementing a cloud radio access network (CRAN)-based architecture design, that separates the baseband processing and radio access functionality to achieve better system synchronization. Second is the overhead for acquiring channel state information (CSI) of the users present in the system, which, however, increases tremendously when instantaneous CSI is used to serve high-mobility users. To serve a large number of users, a CRAN system with a dense deployment of remote radio heads (RRHs) is considered, such that each user has a line-of-sight (LOS) link with the corresponding RRH. Since, the trajectory of movement for high-mobility users is predictable; therefore, fairly accurate position estimates for those users can be obtained, and can be used for resource allocation to serve the considered users. The resource allocation is dependent upon various correlated system parameters, and these correlations can be learned using well-known \\emph{machine learning} algorithms. This paper proposes a novel \\emph{learning-based resource allocation scheme} for time division duplex (TDD) based 5G CRAN systems with dense RRH deployment, by using only the users' position estimates for resource allocation, thus avoiding the need for CSI acquisition. This reduces the overall system overhead significantly, while still achieving near-optimal system performance; thus, better (effective) system efficiency is achieved. (See the paper for full abstract)"}
{"authors": ["Shih-Chieh Su"], "title": "[1608.07619] Interacting with Massive Behavioral Data", "sec_subject": "cs.LG", "url": "http://arxiv.org/abs/1608.07619", "order_index": 8322, "num": 12, "abstract": "In this short paper, we propose the split-diffuse (SD) algorithm that takes the output of an existing word embedding algorithm, and distributes the data points uniformly across the visualization space. The result improves the perceivability and the interactability by the human."}
{"authors": ["Thomas Tanay", "Lewis Griffin"], "title": "[1608.07690] A Boundary Tilting Persepective on the Phenomenon of Adversarial Examples", "sec_subject": "cs.LG", "url": "http://arxiv.org/abs/1608.07690", "order_index": 8318, "num": 8, "abstract": "Deep neural networks have been shown to suffer from a surprising weakness: their classification outputs can be changed by small, non-random perturbations of their inputs. This adversarial example phenomenon has been explained as originating from deep networks being \"too linear\" (Goodfellow et al., 2014). We show here that the linear explanation of adversarial examples presents a number of limitations: the formal argument is not convincing, linear classifiers do not always suffer from the phenomenon, and when they do their adversarial examples are different from the ones affecting deep networks."}
{"authors": ["Hossein Hosseini", "Sreeram Kannan", "Baosen Zhang", "Radha Poovendran"], "title": "[1608.07636] Learning Temporal Dependence from Time-Series Data with Latent Variables", "sec_subject": "cs.LG", "url": "http://arxiv.org/abs/1608.07636", "order_index": 8320, "num": 10, "abstract": "We consider the setting where a collection of time series, modeled as random processes, evolve in a causal manner, and one is interested in learning the graph governing the relationships of these processes. A special case of wide interest and applicability is the setting where the noise is Gaussian and relationships are Markov and linear. We study this setting with two additional features: firstly, each random process has a hidden (latent) state, which we use to model the internal memory possessed by the variables (similar to hidden Markov models). Secondly, each variable can depend on its latent memory state through a random lag (rather than a fixed lag), thus modeling memory recall with differing lags at distinct times. Under this setting, we develop an estimator and prove that under a genericity assumption, the parameters of the model can be learned consistently. We also propose a practical adaption of this estimator, which demonstrates significant performance gains in both synthetic and real-world datasets."}
{"authors": ["Han Xiao", "Minlie Huang", "Xiaoyan Zhu"], "title": "[1608.07685] Knowledge Semantic Representation: A Generative Model for Interpretable Knowledge Graph Embedding", "sec_subject": "cs.LG", "url": "http://arxiv.org/abs/1608.07685", "order_index": 8319, "num": 9, "abstract": "Knowledge representation is a critical topic in AI, and currently embedding as a key branch of knowledge representation takes the numerical form of entities and relations to joint the statistical models. However, most embedding methods merely concentrate on the triple fitting and ignore the explicit semantic expression, leading to an uninterpretable representation form. Thus, traditional embedding methods do not only degrade the performance, but also restrict many potential applications. For this end, this paper proposes a semantic representation method for knowledge graph \\textbf{(KSR)}, which imposes a two-level hierarchical generative process that globally extracts many aspects and then locally assigns a specific category in each aspect for every triple. Because both the aspects and categories are semantics-relevant, the collection of categories in each aspect is treated as the semantic representation of this triple. Extensive experiments justify our model outperforms other state-of-the-art baselines in a substantial extent."}
{"authors": ["Jordan Frecon", "Nelly Pustelnik", "Nicolas Dobigeon", "Herwig Wendt", "Patrice Abry"], "title": "[1608.07739] Bayesian selection for the regularization parameter in TVl0 denoising problems", "sec_subject": "cs.LG", "url": "http://arxiv.org/abs/1608.07739", "order_index": 8315, "num": 5, "abstract": "Piecewise constant denoising can be solved either by deterministic optimization approaches, based on total variation (TV), or by stochastic Bayesian procedures. The former lead to low computational time but requires the selection of a regularization parameter, whose value significantly impacts the achieved solution, and whose automated selection remains an involved and challenging problem. Conversely, fully Bayesian formalisms encapsulate the regularization parameter selection into hierarchical models, at the price of large computational costs. This contribution proposes an operational strategy that combines hierarchical Bayesian and TVl0 formulations, with the double aim of automatically tuning the regularization parameter and of maintaining computational efficiency. The proposed procedure relies on formally connecting a Bayesian framework to a TVl0 minimization formulation. Behaviors and performance for the proposed piecewise constant denoising and regularization parameter tuning techniques are studied qualitatively and assessed quantitatively, and shown to compare favorably against those of a fully Bayesian hierarchical procedure, both in accuracy and in computational load."}
{"authors": ["Yangming Zhou", "Guoping Qiu"], "title": "[1608.07710] Random Forest for Label Ranking", "sec_subject": "cs.LG", "url": "http://arxiv.org/abs/1608.07710", "order_index": 8317, "num": 7, "abstract": "Label ranking aims to learn a mapping from instances to rankings over a finite number of predefined labels. Random forest is a powerful and one of the most successfully general-purpose machine learning algorithms of modern times. In the literature, there seems no research has yet been done in applying random forest to label ranking. In this paper, We present a powerful random forest label ranking method which uses random decision trees to retrieve nearest neighbors that are not only similar in the feature space but also in the ranking space. We have developed a novel two-step rank aggregation strategy to effectively aggregate neighboring rankings discovered by the random forest into a final predicted ranking. Compared with existing methods, the new random forest method has many advantages including its intrinsically scalable tree data structure, highly parallel-able computational architecture and much superior performances. We present extensive experimental results to demonstrate that our new method achieves the best predictive accuracy performances compared with state-of-the-art methods for datasets with complete ranking and datasets with only partial ranking information."}
{"authors": ["Hadi Zare", "Mojtaba Niazi"], "title": "[1608.07934] Relevant based structure learning for feature selection", "sec_subject": "cs.LG", "url": "http://arxiv.org/abs/1608.07934", "order_index": 8312, "num": 2, "abstract": "Feature selection is an important task in many problems occurring in pattern recognition, bioinformatics, machine learning and data mining applications. The feature selection approach enables us to reduce the computation burden and the falling accuracy effect of dealing with huge number of features in typical learning problems. There is a variety of techniques for feature selection in supervised learning problems based on different selection metrics. In this paper, we propose a novel unified framework for feature selection built on the graphical models and information theoretic tools. The proposed approach exploits the structure learning among features to select more relevant and less redundant features to the predictive modeling problem according to a primary novel likelihood based criterion. In line with the selection of the optimal subset of features through the proposed method, it provides us the Bayesian network classifier without the additional cost of model training on the selected subset of features. The optimal properties of our method are established through empirical studies and computational complexity analysis. Furthermore the proposed approach is evaluated on a bunch of benchmark datasets based on the well-known classification algorithms. Extensive experiments confirm the significant improvement of the proposed approach compared to the earlier works."}
{"authors": ["Leandro Aparecido Passos Junior", "Joao Paulo Papa"], "title": "[1608.07719] Temperature-Based Deep Boltzmann Machines", "sec_subject": "cs.LG", "url": "http://arxiv.org/abs/1608.07719", "order_index": 8316, "num": 6, "abstract": "Deep learning techniques have been paramount in the last years, mainly due to their outstanding results in a number of applications, that range from speech recognition to face-based user identification. Despite other techniques employed for such purposes, Deep Boltzmann Machines are among the most used ones, which are composed of layers of Restricted Boltzmann Machines (RBMs) stacked on top of each other. In this work, we evaluate the concept of temperature in DBMs, which play a key role in Boltzmann-related distributions, but it has never been considered in this context up to date. Therefore, the main contribution of this paper is to take into account this information and to evaluate its influence in DBMs considering the task of binary image reconstruction. We expect this work can foster future research considering the usage of different temperatures during learning in DBMs."}
{"authors": ["Bo Li", "Yining Wang", "Aarti Singh", "Yevgeniy Vorobeychik"], "title": "[1608.08182] Data Poisoning Attacks on Factorization-Based Collaborative Filtering", "sec_subject": "cs.LG", "url": "http://arxiv.org/abs/1608.08182", "order_index": 8311, "num": 1, "abstract": "Recommendation and collaborative filtering systems are important in modern information and e-commerce applications. As these systems are becoming increasingly popular in the industry, their outputs could affect business decision making, introducing incentives for an adversarial party to compromise the availability or integrity of such systems. We introduce a data poisoning attack on collaborative filtering systems. We demonstrate how a powerful attacker with full knowledge of the learner can generate malicious data so as to maximize his/her malicious objectives, while at the same time mimicking normal user behavior to avoid being detected. While the complete knowledge assumption seems extreme, it enables a robust assessment of the vulnerability of collaborative filtering schemes to highly motivated attacks. We present efficient solutions for two popular factorization-based collaborative filtering algorithms: the \\emph{alternative minimization} formulation and the \\emph{nuclear norm minimization} method. Finally, we test the effectiveness of our proposed algorithms on real-world data and discuss potential defensive strategies."}
{"authors": ["Wei Fang", "Juei-Yang Hsu", "Hung-yi Lee", "Lin-Shan Lee"], "title": "[1608.07775] Hierarchical Attention Model for Improved Machine Comprehension of Spoken Content", "sec_subject": "cs.CL", "url": "http://arxiv.org/abs/1608.07775", "order_index": 7464, "num": 4, "abstract": "Multimedia or spoken content presents more attractive information than plain text content, but the former is more difficult to display on a screen and be selected by a user. As a result, accessing large collections of the former is much more difficult and time-consuming than the latter for humans. It's therefore highly attractive to develop machines which can automatically understand spoken content and summarize the key information for humans to browse over. In this endeavor, a new task of machine comprehension of spoken content was proposed recently. The initial goal was defined as the listening comprehension test of TOEFL, a challenging academic English examination for English learners whose native languages are not English. An Attention-based Multi-hop Recurrent Neural Network (AMRNN) architecture was also proposed for this task, which considered only the sequential relationship within the speech utterances. In this paper, we propose a new Hierarchical Attention Model (HAM), which constructs multi-hopped attention mechanism over tree-structured rather than sequential representations for the utterances. Improved comprehension performance robust with respect to ASR errors were obtained."}
{"authors": ["Barbara Plank"], "title": "[1608.07836] What to do about non-standard (or non-canonical) language in NLP", "sec_subject": "cs.CL", "url": "http://arxiv.org/abs/1608.07836", "order_index": 7463, "num": 3, "abstract": "Real world data differs radically from the benchmark corpora we use in natural language processing (NLP). As soon as we apply our technologies to the real world, performance drops. The reason for this problem is obvious: NLP models are trained on samples from a limited set of canonical varieties that are considered standard, most prominently English newswire. However, there are many dimensions, e.g., socio-demographics, language, genre, sentence type, etc. on which texts can differ from the standard. The solution is not obvious: we cannot control for all factors, and it is not clear how to best go beyond the current practice of training on homogeneous data from a single domain and language."}
{"authors": ["Enrico Santus", "Emmanuele Chersoni", "Alessandro Lenci", "Chu-Ren Huang", "Philippe Blache"], "title": "[1608.07738] Testing APSyn against Vector Cosine on Similarity Estimation", "sec_subject": "cs.CL", "url": "http://arxiv.org/abs/1608.07738", "order_index": 7465, "num": 5, "abstract": "In Distributional Semantic Models (DSMs), Vector Cosine is widely used to estimate similarity between word vectors, although this measure was noticed to suffer from several shortcomings. The recent literature has proposed other methods which attempt to mitigate such biases. In this paper, we intend to investigate APSyn, a measure that computes the extent of the intersection between the most associated contexts of two target words, weighting it by context relevance. We evaluated this metric in a similarity estimation task on several popular test sets, and our results show that APSyn is in fact highly competitive, even with respect to the results reported in the literature for word embeddings. On top of it, APSyn addresses some of the weaknesses of Vector Cosine, performing well also on genuine similarity estimation."}
{"authors": ["Chao-Lin Liu"], "title": "[1608.07852] Quantitative Analyses of Chinese Poetry of Tang and Song Dynasties: Using Changing Colors and Innovative Terms as Examples", "sec_subject": "cs.CL", "url": "http://arxiv.org/abs/1608.07852", "order_index": 7462, "num": 2, "abstract": "Tang (618-907 AD) and Song (960-1279) dynasties are two very important periods in the development of Chinese literary. The most influential forms of the poetry in Tang and Song were Shi and Ci, respectively. Tang Shi and Song Ci established crucial foundations of the Chinese literature, and their influences in both literary works and daily lives of the Chinese communities last until today."}
{"authors": ["Shuohang Wang", "Jing Jiang"], "title": "[1608.07905] Machine Comprehension Using Match-LSTM and Answer Pointer", "sec_subject": "cs.CL", "url": "http://arxiv.org/abs/1608.07905", "order_index": 7461, "num": 1, "abstract": "Machine comprehension of text is an important problem in natural language processing. A recently released dataset, the Stanford Question Answering Dataset (SQuAD), offers a large number of real questions and their answers created by humans through crowdsourcing. SQuAD provides a challenging testbed for evaluating machine comprehension algorithms, partly because compared with previous datasets, in SQuAD the answers do not come from a small set of candidate answers and they have variable lengths. We propose an end-to-end neural architecture for the task. The architecture is based on match-LSTM, a model we proposed previously for textual entailment, and Pointer Net, a sequence-to-sequence model proposed by Vinyals et al.(2015) to constrain the output tokens to be from the input sequences. We propose two ways of using Pointer Net for our task. Our experiments show that both of our two models substantially outperform the best results obtained by Rajpurkar et al.(2016) using logistic regression and manually crafted features."}
{"authors": ["Ian Gemp", "Sridhar Mahadevan"], "title": "[1608.07888] Online Monotone Optimization", "sec_subject": "cs.LG", "url": "http://arxiv.org/abs/1608.07888", "order_index": 8314, "num": 4, "abstract": "This paper presents a new framework for analyzing and designing no-regret algorithms for dynamic (possibly adversarial) systems. The proposed framework generalizes the popular online convex optimization framework and extends it to its natural limit allowing it to capture a notion of regret that is intuitive for more general problems such as those encountered in game theory and variational inequalities. The framework hinges on a special choice of a system-wide loss function we have developed. Using this framework, we prove that a simple update scheme provides a no-regret algorithm for monotone systems. While previous results in game theory prove individual agents can enjoy unilateral no-regret guarantees, our result proves monotonicity sufficient for guaranteeing no-regret when considering the adjustments of multiple agent strategies in parallel. Furthermore, to our knowledge, this is the first framework to provide a suitable notion of regret for variational inequalities. Most importantly, our proposed framework ensures monotonicity a sufficient condition for employing multiple online learners safely in parallel."}
{"authors": ["Kye-Hyeon Kim", "Yeongjae Cheon", "Sanghoon Hong", "Byungseok Roh", "Minje Park"], "title": "[1608.08021] PVANET: Deep but Lightweight Neural Networks for Real-time Object Detection", "sec_subject": "cs.CV", "url": "http://arxiv.org/abs/1608.08021", "order_index": 7568, "num": 8, "abstract": "This paper presents how we can achieve the state-of-the-art accuracy in multi-category object detection task while minimizing the computational cost by adapting and combining recent technical innovations. Following the common pipeline of \"CNN feature extraction + region proposal + RoI classification\", we mainly redesign the feature extraction part, since region proposal part is not computationally expensive and classification part can be efficiently compressed with common techniques like truncated SVD. Our design principle is \"less channels with more layers\" and adoption of some building blocks including concatenated ReLU, Inception, and HyperNet. The designed network is deep and thin and trained with the help of batch normalization, residual connections, and learning rate scheduling based on plateau detection. We obtained solid results on well-known object detection benchmarks: 81.8% mAP (mean average precision) on VOC2007 and 82.5% mAP on VOC2012 (2nd place), while taking only 750ms/image on Intel i7-6700K CPU with a single core and 46ms/image on NVIDIA Titan X GPU. Theoretically, our network requires only 12.3% of the computational cost compared to ResNet-101, the winner on VOC2012."}
{"authors": ["William X. Liu", "Tat-Jun Chin"], "title": "[1608.07997] Correspondence Insertion for As-Projective-As-Possible Image Stitching", "sec_subject": "cs.CV", "url": "http://arxiv.org/abs/1608.07997", "order_index": 7569, "num": 9, "abstract": "Spatially varying warps are increasingly popular for image alignment. In particular, as-projective-as-possible (APAP) warps have been proven effective for accurate panoramic stitching, especially in cases with significant depth parallax that defeat standard homographic warps. However, estimating spatially varying warps requires a sufficient number of feature matches. In image regions where feature detection or matching fail, the warp loses guidance and is unable to accurately model the true underlying warp, thus resulting in poor registration. In this paper, we propose a correspondence insertion method for APAP warps, with a focus on panoramic stitching. Our method automatically identifies misaligned regions, and inserts appropriate point correspondences to increase the flexibility of the warp and improve alignment. Unlike other warp varieties, the underlying projective regularization of APAP warps reduces overfitting and geometric distortion, despite increases to the warp complexity. Comparisons with recent techniques for parallax-tolerant image stitching demonstrate the effectiveness and simplicity of our approach."}
{"authors": ["Olfa Nasraoui", "Patrick Shafto"], "title": "[1608.07895] Human-Algorithm Interaction Biases in the Big Data Cycle: A Markov Chain Iterated Learning Framework", "sec_subject": "cs.LG", "url": "http://arxiv.org/abs/1608.07895", "order_index": 8313, "num": 3, "abstract": "Early supervised machine learning algorithms have relied on reliable expert labels to build predictive models. However, the gates of data generation have recently been opened to a wider base of users who started participating increasingly with casual labeling, rating, annotating, etc. The increased online presence and participation of humans has led not only to a democratization of unchecked inputs to algorithms, but also to a wide democratization of the \"consumption\" of machine learning algorithms' outputs by general users. Hence, these algorithms, many of which are becoming essential building blocks of recommender systems and other information filters, started interacting with users at unprecedented rates. The result is machine learning algorithms that consume more and more data that is unchecked, or at the very least, not fitting conventional assumptions made by various machine learning algorithms. These include biased samples, biased labels, diverging training and testing sets, and cyclical interaction between algorithms, humans, information consumed by humans, and data consumed by algorithms. Yet, the continuous interaction between humans and algorithms is rarely taken into account in machine learning algorithm design and analysis. In this paper, we present a preliminary theoretical model and analysis of the mutual interaction between humans and algorithms, based on an iterated learning framework that is inspired from the study of human language evolution. We also define the concepts of human and algorithm blind spots and outline machine learning approaches to mend iterated bias through two novel notions: antidotes and reactive learning."}
{"authors": ["Cem Aksoylar", "Jing Qian", "Venkatesh Saligrama"], "title": "[1608.07605] Clustering and Community Detection with Imbalanced Clusters", "sec_subject": "cs.LG", "url": "http://arxiv.org/abs/1608.07605", "order_index": 8329, "num": 19, "abstract": "Spectral clustering methods which are frequently used in clustering and community detection applications are sensitive to the specific graph constructions particularly when imbalanced clusters are present. We show that ratio cut (RCut) or normalized cut (NCut) objectives are not tailored to imbalanced cluster sizes since they tend to emphasize cut sizes over cut values. We propose a graph partitioning problem that seeks minimum cut partitions under minimum size constraints on partitions to deal with imbalanced cluster sizes. Our approach parameterizes a family of graphs by adaptively modulating node degrees on a fixed node set, yielding a set of parameter dependent cuts reflecting varying levels of imbalance. The solution to our problem is then obtained by optimizing over these parameters. We present rigorous limit cut analysis results to justify our approach and demonstrate the superiority of our method through experiments on synthetic and real datasets for data clustering, semi-supervised learning and community detection."}
{"authors": ["Samaneh Abbasi-Sureshjani", "Marta Favali", "Giovanna Citti", "Alessandro Sarti", "Bart M. ter Haar Romeny"], "title": "[1608.08049] Cortically-Inspired Spectral Clustering for Connectivity Analysis in Retinal Images: Curvature Integration", "sec_subject": "cs.CV", "url": "http://arxiv.org/abs/1608.08049", "order_index": 7566, "num": 6, "abstract": "Tree-like structures such as retinal images are widely studied in computer-aided diagnosis systems in large-scale screening programs. Despite several segmentation and tracking methods proposed in the literature, there still exist several limitations specifically when two or more curvilinear structures cross or bifurcate, or in the presence of interrupted lines or highly curved blood vessels. In this paper, we propose a novel approach based on multi-orientation scores augmented with a contextual affinity matrix, which both are inspired by the geometry of the primary visual cortex (V1) and their contextual connections. The connectivity is described with a four-dimensional kernel obtained as the fundamental solution of the Fokker-Planck equation modelling the cortical connectivity in the lifted space of positions, orientations and curvatures. It is further used in a self-tuning spectral clustering step to identify the main perceptual units in the stimuli. The proposed method has been validated on several easy and challenging structures in a set of artificial images and actual retinal patches. Supported by quantitative and qualitative results, the method is capable of overcoming the limitations of current state-of-the-art techniques."}
{"authors": ["Xiaozhi Chen", "Kaustav Kundu", "Yukun Zhu", "Huimin Ma", "Sanja Fidler", "Raquel Urtasun"], "title": "[1608.07711] 3D Object Proposals using Stereo Imagery for Accurate Object Class Detection", "sec_subject": "cs.CV", "url": "http://arxiv.org/abs/1608.07711", "order_index": 7579, "num": 19, "abstract": "The goal of this paper is to perform 3D object detection in the context of autonomous driving. Our method first aims at generating a set of high-quality 3D object proposals by exploiting stereo imagery. We formulate the problem as minimizing an energy function that encodes object size priors, placement of objects on the ground plane as well as several depth informed features that reason about free space, point cloud densities and distance to the ground. We then exploit a CNN on top of these proposals to perform object detection. In particular, we employ a convolutional neural net (CNN) that exploits context and depth information to jointly regress to 3D bounding box coordinates and object pose. Our experiments show significant performance gains over existing RGB and RGB-D object proposal methods on the challenging KITTI benchmark. When combined with the CNN, our approach outperforms all existing results in object detection and orientation estimation tasks for all three KITTI object classes. Furthermore, we experiment also with the setting where LIDAR information is available, and show that using both LIDAR and stereo leads to the best result."}
{"authors": ["Xiang Wang", "Huimin Ma", "Shaodi You", "Xiaozhi Chen"], "title": "[1608.08029] Edge Preserving and Multi-Scale Contextual Neural Network for Salient Object Detection", "sec_subject": "cs.CV", "url": "http://arxiv.org/abs/1608.08029", "order_index": 7567, "num": 7, "abstract": "In this paper, we propose a novel edge preserving and multi-scale contextual neural network for salient object detection. The proposed framework is aiming to address two limits of the existing CNN based methods. First, region-based CNN methods lack sufficient context to accurately locate salient object since they deal with each region independently. Second, pixel-based CNN methods suffer from blurry boundaries due to the presence of convolutional and pooling layers. Motivated by these, we first propose an end-to-end edge-preserved neural network based on Fast R-CNN framework (named RegionNet) to efficiently generate saliency map with sharp object boundaries. Later, to further improve it, multi-scale spatial context is attached to RegionNet to consider the relationship between regions and the global scenes. Furthermore, our method can be generally applied to RGB-D saliency detection by depth refinement. The proposed framework achieves both clear detection boundary and multi-scale contextual robustness simultaneously for the first time, and thus achieves an optimized performance. Experiments on six RGB and two RGB-D benchmark datasets demonstrate that the proposed method outperforms previous methods by a large margin, in particular, we achieve relative improvement by 6.1% and 10.1% on F-measure on ECSSD and DUT-OMRON dataset, respectively."}
{"authors": ["Alberto Montes", "Amaia Salvador", "Xavier Giro-i-Nieto"], "title": "[1608.08128] Temporal Activity Detection in Untrimmed Videos with Recurrent Neural Networks", "sec_subject": "cs.CV", "url": "http://arxiv.org/abs/1608.08128", "order_index": 7564, "num": 4, "abstract": "This thesis explore different approaches using Convolutional and Recurrent Neural Networks to classify and temporally localize activities on videos, furthermore an implementation to achieve it has been proposed. As the first step, features have been extracted from video frames using an state of the art 3D Convolutional Neural Network. This features are fed in a recurrent neural network that solves the activity classification and temporally location tasks in a simple and flexible way. Different architectures and configurations have been tested in order to achieve the best performance and learning of the video dataset provided. In addition it has been studied different kind of post processing over the trained network's output to achieve a better results on the temporally localization of activities on the videos. The results provided by the neural network developed in this thesis have been submitted to the ActivityNet Challenge 2016 of the CVPR, achieving competitive results using a simple and flexible architecture."}
{"authors": ["Cristian Reyes", "Eva Mohedano", "Kevin McGuinness", "Noel E. O'Connor", "Xavier Giro-i-Nieto"], "title": "[1608.08139] Where is my Phone ? Personal Object Retrieval from Egocentric Images", "sec_subject": "cs.CV", "url": "http://arxiv.org/abs/1608.08139", "order_index": 7585, "num": 25, "abstract": "This work presents a retrieval pipeline and evaluation scheme for the problem of finding the last appearance of personal objects in a large dataset of images captured from a wearable camera. Each personal object is modelled by a small set of images that define a query for a visual search engine.The retrieved results are reranked considering the temporal timestamps of the images to increase the relevance of the later detections. Finally, a temporal interleaving of the results is introduced for robustness against false detections. The Mean Reciprocal Rank is proposed as a metric to evaluate this problem. This application could help into developing personal assistants capable of helping users when they do not remember where they left their personal belongings."}
